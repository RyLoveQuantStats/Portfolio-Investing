Directory structure:
└── Portfolio Investing/
    ├── NQ_Efficient_Frontier_Project_Outline.docx
    ├── portfolio_risk_metrics.xlsx
    ├── notebooks/
    │   ├── Finance_Academy_Project.ipynb
    │   ├── portfolio_risk_metrics.xlsx
    │   └── output/
    ├── old_scripts/
    │   ├── bonds.py
    │   ├── config.py
    │   ├── equities.py
    │   └── options.py
    ├── output/
    └── scripts/
        ├── portfolio.py
        ├── visuals.py
        └── __pycache__/

================================================
File: NQ_Efficient_Frontier_Project_Outline.docx
================================================
[Non-text file]


================================================
File: portfolio_risk_metrics.xlsx
================================================
[Non-text file]


================================================
File: notebooks/Finance_Academy_Project.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# --- Finance Academy: Portfolio Investing ---
# Authors: Ryan Loveless, Inigo Abascal, Carmello Maggio
# April 2025
"""

# Import Required Libraries

import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
from scipy.stats import norm
from datetime import timedelta

# PyPortfolioOpt imports:
from pypfopt import EfficientFrontier, risk_models, expected_returns
import scipy.optimize as opt

# Configuration & Assumptions

Start_Date = "2019-06-01"
End_Date   = "2024-12-31"
risk_free_equity = 0.02      # For CAPM & Sharpe (annual)
risk_free_option = 0.01      # For Black-Scholes pricing (annual)
shares_per_contract = 100
transaction_cost = 0.001     # 0.1% per trade cost

# Parameters for covered call enhancements:
# (Using delta-targeting, the target delta is our key input)
target_delta = 0.3           # Initial target delta (to be optimized)
threshold_vol_option = 0.25  # Initial threshold volatility (annual) for option term decision
short_option_term = 60       # Option term (days) in high volatility periods
long_option_term = 90        # Option term (days) in low volatility periods

# Dynamic weight allocation parameters (for combined portfolio)
high_equity_weight = 0.70    # When SPY volatility is low
low_equity_weight = 0.45     # When SPY volatility is high
vol_threshold = 0.25         # SPY volatility threshold (annual)

# Sector ETF list and SPY Benchmark
etf_list = ['XLY', 'XLP', 'XLE', 'XLF', 'XLV',
            'XLI', 'XLB', 'XLRE', 'XLK', 'XLU', 'XLC']
benchmark_ticker = 'SPY'

"""
# --- Helper Functions ---
"""

def compute_dynamic_base_buffer(S, sigma, T, r, target_yield=0.015, min_b=0.01, max_b=0.15, step=0.005):
    """
    Compute a dynamic base strike buffer such that the theoretical option premium yield 
    is as close as possible to the target_yield.
    """
    best_b = min_b
    best_diff = float('inf')
    for b in np.arange(min_b, max_b + step, step):
        K = S * (1 + b)
        premium = black_scholes_call(S, K, T, r, sigma)
        yield_est = premium / (S * shares_per_contract)
        diff = abs(yield_est - target_yield)
        if diff < best_diff:
            best_diff = diff
            best_b = b
    return best_b

def delta_targeted_strike(S, T, r, sigma, target_delta=target_delta):
    """
    Compute the call strike K such that under the Black-Scholes model the call delta is equal to target_delta.
    
    K = S * exp(-σ√T * N⁻¹(target_delta) + (r + 0.5σ²)T)
    """
    d_target = norm.ppf(target_delta)
    K = S * np.exp(-sigma * np.sqrt(T) * d_target + (r + 0.5 * sigma**2)*T)
    return K

def dynamic_option_term(sigma, threshold=threshold_vol_option, short_term=short_option_term, long_term=long_option_term):
    """
    Choose option term in days based on current annualized volatility.
    """
    return long_term if sigma < threshold else short_term

def dynamic_weight_allocation(current_vol, low=low_equity_weight, high=high_equity_weight, threshold=vol_threshold):
    """
    Adjust overall equity allocation based on SPY's recent annualized volatility.
    """
    return low if current_vol >= threshold else high

def compute_sector_weights(price_data, etfs, lookback_days=126):
    """
    Compute weights for each ETF based on trailing 6-month performance.
    Negative returns are clipped to zero.
    """
    last_date = price_data.index.max()
    start_date = last_date - pd.Timedelta(days=lookback_days)
    trailing_return = price_data.loc[start_date:last_date, etfs].iloc[-1] / price_data.loc[start_date:last_date, etfs].iloc[0] - 1
    trailing_return = trailing_return.clip(lower=0)
    if trailing_return.sum() == 0:
        weights = pd.Series(1/len(etfs), index=etfs)
    else:
        weights = trailing_return / trailing_return.sum()
    return weights

# --- Black-Scholes Call Option Pricing ---
def black_scholes_call(S, K, T, r, sigma):
    """
    Calculate the Black-Scholes price for a European call option.
    """
    if T <= 0 or sigma <= 0:
        return max(S - K, 0.0)
    d1 = (np.log(S / K) + (r + 0.5 * sigma**2)*T) / (sigma * np.sqrt(T))
    d2 = d1 - sigma * np.sqrt(T)
    return S * norm.cdf(d1) - K * np.exp(-r*T) * norm.cdf(d2)

"""
# --- Covered Calls ---
"""

# --- Covered Call Simulation for a Single ETF ---
def simulate_covered_call_for_etf(ticker, price_series):
    """
    Simulate daily portfolio values for a covered call strategy on one ETF.
    Uses delta-targeted strike selection and a dynamic option term.
    """
    df = pd.DataFrame({'Price': price_series.dropna()})
    df['LogReturn'] = np.log(df['Price'] / df['Price'].shift(1))
    df['Volatility'] = df['LogReturn'].rolling(window=30).std() * np.sqrt(252)
    df.dropna(inplace=True)
    
    # Monthly option sale dates: first trading day of each month.
    monthly_dates = df.resample('MS').first().index
    monthly_dates = [d for d in monthly_dates if d in df.index]
    
    shares = shares_per_contract
    cash = 0.0
    portfolio_values = []
    dates = []
    active_calls = []  # Each call: {'strike': K, 'expiration': date}
    
    for current_date in df.index:
        S = df.at[current_date, 'Price']
        sigma = df.at[current_date, 'Volatility']
        portfolio_val = cash + shares * S
        dates.append(current_date)
        portfolio_values.append(portfolio_val)
        
        # Check expiration of active options.
        for pos in list(active_calls):
            if current_date >= pos['expiration']:
                K = pos['strike']
                if S > K and shares > 0:
                    cash += shares * K
                    shares = 0
                active_calls.remove(pos)
        
        if current_date in monthly_dates:
            if shares == 0:
                shares = shares_per_contract
                cash -= shares * S
                cash -= (shares * S) * transaction_cost
            # Determine option term dynamically.
            opt_term = dynamic_option_term(sigma)
            T = opt_term / 252.0
            # Use delta-targeted strike selection.
            K = delta_targeted_strike(S, T, risk_free_option, sigma, target_delta=target_delta)
            premium = black_scholes_call(S, K, T, risk_free_option, sigma) * shares_per_contract
            cash += premium
            cash -= (shares * S) * transaction_cost
            expiration_date = current_date + pd.Timedelta(days=opt_term)
            active_calls.append({'strike': K, 'expiration': expiration_date})
    
    return pd.Series(portfolio_values, index=dates)

# --- Covered Call Portfolio ---
def simulate_covered_calls_portfolio(etfs, price_data):
    """
    Run the covered call simulation for each ETF and combine the results using performance-based weights.
    Returns a normalized daily series.
    """
    portfolios = {}
    for ticker in etfs:
        try:
            prices = price_data[ticker]
            portfolios[ticker] = simulate_covered_call_for_etf(ticker, prices)
        except Exception as e:
            print(f"Warning: Simulation for {ticker} failed: {e}")
    if not portfolios:
        raise ValueError("No ETF data available for covered call simulation.")
    sector_weights = compute_sector_weights(price_data, etfs, lookback_days=126)
    combined_df = pd.DataFrame(portfolios).sort_index().ffill()
    weighted_portfolio = combined_df.multiply(sector_weights, axis=1).sum(axis=1)
    normalized = weighted_portfolio / weighted_portfolio.iloc[0]
    return normalized

"""
# --- Equity Portfolio Simulation ---
"""

def simulate_equity_portfolio(etfs, benchmark, price_data, calib_years=2):
    """
    Simulate a quarterly-rebalanced equity portfolio using a rolling calibration window and PyPortfolioOpt.
    Returns a normalized daily series.
    """
    daily_returns = price_data.pct_change().dropna()
    rebalance_dates = daily_returns.resample('QS').first().index
    rebalance_dates = [d for d in rebalance_dates if d >= daily_returns.index[0]]
    
    dates = []
    values = []
    current_value = 1.0
    
    for i, rebalance_date in enumerate(rebalance_dates):
        if rebalance_date > daily_returns.index[-1]:
            break
        window_start = rebalance_date - pd.DateOffset(years=calib_years)
        calib_data = daily_returns.loc[window_start:rebalance_date]
        mu = expected_returns.mean_historical_return(price_data.loc[window_start:rebalance_date], frequency=252)
        Sigma = risk_models.sample_cov(price_data.loc[window_start:rebalance_date], frequency=252)
        ef = EfficientFrontier(mu, Sigma, weight_bounds=(0, 1))
        ef.max_sharpe(risk_free_equity)
        weights = ef.clean_weights()
        optimal_weights = pd.Series(weights)
        if i > 0:
            current_value *= (1 - transaction_cost)
        
        if i < len(rebalance_dates) - 1:
            next_start = rebalance_dates[i + 1]
            period_idx = daily_returns.index[daily_returns.index < next_start]
            period_end = period_idx[-1] if len(period_idx) > 0 else daily_returns.index[-1]
        else:
            period_end = daily_returns.index[-1]
        
        period_returns = daily_returns.loc[rebalance_date:period_end, etfs]
        if rebalance_date not in period_returns.index:
            dates.append(rebalance_date)
            values.append(current_value)
        for day in period_returns.index:
            if day == rebalance_date:
                dates.append(day)
                values.append(current_value)
            daily_ret = np.dot(period_returns.loc[day, etfs], optimal_weights[etfs])
            current_value *= (1 + daily_ret)
            dates.append(day)
            values.append(current_value)
    
    equity_portfolio = pd.Series(values, index=dates)
    equity_portfolio = equity_portfolio[~equity_portfolio.index.duplicated(keep='first')]
    equity_index = equity_portfolio / equity_portfolio.iloc[0]
    return equity_index

"""
# --- Bootstrap Sensitivity Analysis & Risk Metrics ---
"""

def bootstrap_sensitivity(index_series, n_iter=1000, sample_frac=0.5):
    """
    Perform bootstrap resampling on the portfolio's daily returns to assess sensitivity.
    Returns a DataFrame with bootstrap distributions of risk metrics.
    """
    returns = index_series.pct_change().dropna()
    metrics_list = []
    for _ in range(n_iter):
        sample = returns.sample(frac=sample_frac, replace=True)
        sample_series = (1 + sample).cumprod()
        metrics_list.append(compute_risk_metrics(sample_series))
    bootstrap_df = pd.DataFrame(metrics_list, columns=["Cumulative Return", "Annual Return", "Volatility", "Sharpe", "Max Drawdown"])
    return bootstrap_df

def compute_risk_metrics(index_series, risk_free=0.02):
    """
    Compute risk metrics for a normalized index series.
    Returns cumulative return, annualized return, annual volatility, Sharpe ratio, and max drawdown.
    """
    returns = index_series.pct_change().dropna()
    cumulative_return = index_series.iloc[-1] / index_series.iloc[0] - 1
    annual_factor = 252
    annual_return = (index_series.iloc[-1] / index_series.iloc[0])**(annual_factor/len(index_series)) - 1
    ann_vol = returns.std() * np.sqrt(annual_factor)
    sharpe = (annual_return - risk_free) / (ann_vol if ann_vol != 0 else np.nan)
    running_max = index_series.cummax()
    drawdown = (index_series - running_max) / running_max
    max_drawdown = drawdown.min()
    return cumulative_return, annual_return, ann_vol, sharpe, max_drawdown

"""
# --- Optimize Assumptions ---
"""

def objective(params, price_data):
    """
    Objective function to be minimized (negative Sharpe ratio) given a vector of parameters.
    Parameters vector:
      params[0]: target_delta
      params[1]: threshold_vol_option
      params[2]: short_option_term (days)
      params[3]: long_option_term (days)
      params[4]: high_equity_weight
      params[5]: low_equity_weight
      params[6]: vol_threshold
    """
    global target_delta, threshold_vol_option, short_option_term, long_option_term, high_equity_weight, low_equity_weight, vol_threshold
    target_delta = params[0]
    threshold_vol_option = params[1]
    short_option_term = int(round(params[2]))
    long_option_term = int(round(params[3]))
    high_equity_weight = params[4]
    low_equity_weight = params[5]
    vol_threshold = params[6]
    
    try:
        equity_index = simulate_equity_portfolio(etf_list, benchmark_ticker, price_data)
        covered_call_index = simulate_covered_calls_portfolio(etf_list, price_data)
    
        common_start = max(equity_index.index.min(), covered_call_index.index.min())
        full_dates = pd.date_range(start=common_start, end=price_data.index.max(), freq='B')
    
        equity_index_full = equity_index.reindex(full_dates).ffill().bfill()
        covered_call_index_full = covered_call_index.reindex(full_dates).ffill().bfill()
    
        equity_daily_ret = equity_index_full.pct_change().fillna(0)
        option_daily_ret = covered_call_index_full.pct_change().fillna(0)
    
        spy_prices = price_data[benchmark_ticker]
        spy_returns = spy_prices.pct_change().dropna()
        spy_vol = spy_returns.rolling(window=30).std().iloc[-1] * np.sqrt(252)
        dyn_equity_weight = dynamic_weight_allocation(spy_vol)
    
        combined_daily_ret = dyn_equity_weight * equity_daily_ret + (1 - dyn_equity_weight) * option_daily_ret
        combined_index = (1 + combined_daily_ret).cumprod()
    
        _, _, _, sharpe, _ = compute_risk_metrics(combined_index, risk_free=risk_free_equity)
    except Exception as e:
        sharpe = -100  # Penalize if simulation fails
    
    if np.isnan(sharpe):
        return 1000
    return -sharpe  # We want to maximize Sharpe, so minimize negative Sharpe

# Define bounds for each parameter
bounds = [
    (0.25, 0.55),    # target_delta
    (0.15, 0.30),    # threshold_vol_option
    (20, 90),        # short_option_term (days)
    (30, 120),       # long_option_term (days)
    (0.60, 0.80),    # high_equity_weight
    (0.10, 0.50),    # low_equity_weight
    (0.20, 0.40)     # vol_threshold
]

"""
# --- Main Execution ---
"""

if __name__ == "__main__":
    # Download historical price data.
    all_tickers = etf_list + [benchmark_ticker]
    price_data = yf.download(all_tickers, start=Start_Date, end=End_Date, auto_adjust=True)['Close']
    price_data.dropna(inplace=True)
    
    # Run current simulations and print risk metrics.
    equity_index = simulate_equity_portfolio(etf_list, benchmark_ticker, price_data)
    covered_call_index = simulate_covered_calls_portfolio(etf_list, price_data)
    
    common_start = max(equity_index.index.min(), covered_call_index.index.min())
    full_dates = pd.date_range(start=common_start, end=price_data.index.max(), freq='B')
    
    equity_index_full = equity_index.reindex(full_dates).ffill().bfill()
    covered_call_index_full = covered_call_index.reindex(full_dates).ffill().bfill()
    equity_daily_ret = equity_index_full.pct_change().fillna(0)
    option_daily_ret = covered_call_index_full.pct_change().fillna(0)
    
    spy_prices = price_data[benchmark_ticker]
    spy_returns = spy_prices.pct_change().dropna()
    spy_vol = spy_returns.rolling(window=30).std().iloc[-1] * np.sqrt(252)
    dyn_equity_weight = dynamic_weight_allocation(spy_vol)
    print(f"Dynamic equity weight based on SPY volatility ({spy_vol:.2%}): {dyn_equity_weight:.2f}")
    
    combined_daily_ret = dyn_equity_weight * equity_daily_ret + (1 - dyn_equity_weight) * option_daily_ret
    combined_index = (1 + combined_daily_ret).cumprod()
    spy_index = (price_data[benchmark_ticker] / price_data[benchmark_ticker].iloc[0]).reindex(full_dates).ffill().bfill()
    
    strategies = {
        'Equity Portfolio': equity_index_full,
        'Covered Call Strategy': covered_call_index_full,
        'Combined Portfolio': combined_index,
        'SPY Buy & Hold': spy_index
    }
    metrics = []
    for name, series in strategies.items():
        cum_ret, ann_ret, ann_vol, sharpe, max_dd = compute_risk_metrics(series, risk_free=risk_free_equity)
        metrics.append({
            "Strategy": name,
            "Cumulative Return (%)": cum_ret * 100,
            "Annualized Return (%)": ann_ret * 100,
            "Annualized Volatility (%)": ann_vol * 100,
            "Sharpe Ratio": sharpe,
            "Max Drawdown (%)": max_dd * 100
        })
    metrics_df = pd.DataFrame(metrics)
    print("\nRisk Metrics Comparison:")
    print(metrics_df)
    excel_filename = "portfolio_risk_metrics.xlsx"
    metrics_df.to_excel(excel_filename, index=False)
    print(f"\nRisk metrics have been written to {excel_filename}")
    
    bootstrap_results = bootstrap_sensitivity(combined_index, n_iter=500, sample_frac=0.5)
    print("\nBootstrap Sensitivity Analysis (first 5 rows):")
    print(bootstrap_results.head())
    
    # --- Optimization ---
    # Use differential evolution to optimize the covered call parameters (and dynamic weight allocation parameters)
    '''
    result = opt.differential_evolution(objective, bounds, args=(price_data,), maxiter=50, tol=0.01, disp=True)
    print("\nOptimized Parameters:")
    print("target_delta:", result.x[0])
    print("threshold_vol_option:", result.x[1])
    print("short_option_term:", int(round(result.x[2])))
    print("long_option_term:", int(round(result.x[3])))
    print("high_equity_weight:", result.x[4])
    print("low_equity_weight:", result.x[5])
    print("vol_threshold:", result.x[6])
    print("Max Sharpe achieved:", -result.fun)
    '''
# Output:
#   [*********************100%***********************]  12 of 12 completed

#   Dynamic equity weight based on SPY volatility (13.04%): 0.70

#   

#   Risk Metrics Comparison:

#                   Strategy  Cumulative Return (%)  Annualized Return (%)  \

#   0       Equity Portfolio             116.549237              14.641153   

#   1  Covered Call Strategy             162.870859              18.639180   

#   2     Combined Portfolio             134.059405              16.228439   

#   3         SPY Buy & Hold             113.663347              14.369482   

#   

#      Annualized Volatility (%)  Sharpe Ratio  Max Drawdown (%)  

#   0                  24.710571      0.511569        -32.613463  

#   1                  18.080073      0.920305        -20.609662  

#   2                  21.351087      0.666403        -28.973307  

#   3                  20.067729      0.616387        -33.717262  

#   

#   Risk metrics have been written to portfolio_risk_metrics.xlsx

#   

#   Bootstrap Sensitivity Analysis (first 5 rows):

#      Cumulative Return  Annual Return  Volatility    Sharpe  Max Drawdown

#   0           0.892298       0.253244    0.206035  1.132062     -0.264207

#   1           1.766972       0.433639    0.201964  2.048080     -0.179012

#   2          -0.060100      -0.021698    0.213170 -0.195610     -0.284101

#   3           0.095472       0.032800    0.206606  0.061954     -0.232115

#   4           1.311945       0.345313    0.220823  1.473188     -0.253026


"""
# --- Visualization ---
"""

import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
import seaborn as sns

# --- Configuration (should match portfolio.py) ---
Start_Date = "2019-06-01"
End_Date   = "2024-12-31"
benchmark_ticker = 'SPY'
etf_list = ['XLY', 'XLP', 'XLE', 'XLF', 'XLV',
            'XLI', 'XLB', 'XLRE', 'XLK', 'XLU', 'XLC']

# --- Data Acquisition ---
print("Fetching historical price data...")
all_tickers = etf_list + [benchmark_ticker]
price_data = yf.download(all_tickers, start=Start_Date, end=End_Date, auto_adjust=True)['Close']
price_data.dropna(inplace=True)

# --- Run Portfolio Simulations ---
print("Running portfolio simulations...")
equity_index = simulate_equity_portfolio(etf_list, benchmark_ticker, price_data)
covered_call_index = simulate_covered_calls_portfolio(etf_list, price_data)

# Define common date range from the later of the two series' first dates.
common_start = max(equity_index.index.min(), covered_call_index.index.min())
full_dates = pd.date_range(start=common_start, end=price_data.index.max(), freq='B')

equity_index_full = equity_index.reindex(full_dates).ffill().bfill()
covered_call_index_full = covered_call_index.reindex(full_dates).ffill().bfill()

# Compute daily returns for each strategy.
equity_daily_ret = equity_index_full.pct_change().fillna(0)
option_daily_ret = covered_call_index_full.pct_change().fillna(0)

# Prepare SPY normalized series on the same date range.
spy_index = price_data[benchmark_ticker].reindex(full_dates).ffill().bfill()
spy_index = spy_index / spy_index.iloc[0]

# Compute dynamic equity allocation using SPY volatility.
spy_returns = spy_index.pct_change().dropna()
spy_vol = spy_returns.rolling(window=30).std().iloc[-1] * np.sqrt(252)
dyn_equity_weight = dynamic_weight_allocation(spy_vol)
print(f"Dynamic equity weight based on SPY volatility ({spy_vol:.2%}): {dyn_equity_weight:.2f}")

# Combine equity and covered call strategies using the dynamic equity weight.
combined_daily_ret = dyn_equity_weight * equity_daily_ret + (1 - dyn_equity_weight) * option_daily_ret
combined_index = (1 + combined_daily_ret).cumprod()

# Create a dictionary with strategy series.
strategies = {
    "Equity Portfolio": equity_index_full,
    "Covered Call Strategy": covered_call_index_full,
    "Combined Portfolio": combined_index,
    "SPY Buy & Hold": spy_index
}

# --- Visualization Functions ---

def plot_cumulative_returns(strategy_dict):
    plt.figure(figsize=(12, 7))
    for label, series in strategy_dict.items():
        plt.plot(series.index, series.values, label=label)
    plt.title("Cumulative Returns Comparison")
    plt.xlabel("Date")
    plt.ylabel("Normalized Value (Base = 1.0)")
    plt.legend(loc="best")
    plt.grid(True)
    plt.savefig("output/cumulative_returns.png")

def plot_daily_return_histograms(daily_returns_dict):
    """Plot histograms for daily returns for each strategy, filtering out non-finite values."""
    plt.figure(figsize=(14, 8))
    for i, (label, daily_ret) in enumerate(daily_returns_dict.items()):
        # Filter out any non-finite values
        daily_ret = daily_ret[np.isfinite(daily_ret)]
        if daily_ret.empty:
            print(f"Warning: {label} daily returns are empty or contain no finite values.")
            continue
        plt.subplot(2, 2, i+1)
        plt.hist(daily_ret, bins=50, alpha=0.75, color="skyblue")
        plt.title(f"Daily Returns: {label}")
        plt.xlabel("Return")
        plt.ylabel("Frequency")
    plt.tight_layout()
    plt.savefig("output/daily_return_histograms.png")

def plot_drawdown_curves(strategy_dict):
    plt.figure(figsize=(12, 7))
    for label, series in strategy_dict.items():
        running_max = series.cummax()
        drawdown = (series - running_max) / running_max
        plt.plot(drawdown.index, drawdown.values, label=label)
    plt.title("Drawdown Curves")
    plt.xlabel("Date")
    plt.ylabel("Drawdown")
    plt.legend(loc="best")
    plt.grid(True)
    plt.savefig("output/drawdown_curves.png")

def plot_rolling_metrics(series, window=60):
    daily_ret = series.pct_change().dropna()
    rolling_vol = daily_ret.rolling(window=window).std() * np.sqrt(252)
    # Compute rolling cumulative return over the window
    rolling_return = (1 + daily_ret).rolling(window=window).apply(np.prod, raw=True) - 1
    rolling_sharpe = (rolling_return - risk_free_equity) / rolling_vol
    fig, ax1 = plt.subplots(figsize=(12, 7))
    ax1.plot(rolling_vol.index, rolling_vol, color="blue", label="Rolling Volatility")
    ax1.set_ylabel("Volatility", color="blue")
    ax1.tick_params(axis="y", labelcolor="blue")
    ax2 = ax1.twinx()
    ax2.plot(rolling_sharpe.index, rolling_sharpe, color="red", label="Rolling Sharpe")
    ax2.set_ylabel("Sharpe Ratio", color="red")
    ax2.tick_params(axis="y", labelcolor="red")
    plt.title(f"Rolling {window}-Day Volatility & Sharpe Ratio (Combined Portfolio)")
    fig.legend(loc="upper right", bbox_to_anchor=(1,1))
    plt.savefig("output/rolling_metrics.png")

def plot_correlation_heatmap(daily_returns_dict):
    data = {}
    for label, ret in daily_returns_dict.items():
        data[label] = ret
    returns_df = pd.DataFrame(data)
    corr_matrix = returns_df.corr()
    plt.figure(figsize=(8, 6))
    sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", vmin=-1, vmax=1)
    plt.title("Correlation Heatmap of Daily Returns")
    plt.savefig("output/correlation_heatmap.png")

def plot_bootstrap_histograms(bootstrap_df):
    plt.figure(figsize=(14, 8))
    metrics = bootstrap_df.columns
    for i, met in enumerate(metrics):
        plt.subplot(2, 3, i+1)
        plt.hist(bootstrap_df[met].dropna(), bins=30, alpha=0.75, color="purple")
        plt.title(f"Bootstrap Distribution: {met}")
        plt.xlabel(met)
        plt.ylabel("Frequency")
    plt.tight_layout()
    plt.savefig("output/bootstrap_histograms.png")

def plot_sector_weights(sector_weights):
    plt.figure(figsize=(10, 6))
    sector_weights.sort_values(ascending=False).plot(kind="bar", color="green")
    plt.title("Performance-based Sector Weights (Trailing 6 Months)")
    plt.xlabel("ETF")
    plt.ylabel("Weight")
    plt.grid(True)
    plt.savefig("output/sector_weights.png")

# --- Generate Visualizations ---
print("Generating visualizations...")

# 1. Plot Cumulative Returns
plot_cumulative_returns(strategies)

# 2. Plot Daily Return Histograms
daily_returns_strategies = {
    "Equity": equity_index_full.pct_change().dropna(),
    "Covered Call": covered_call_index_full.pct_change().dropna(),
    "Combined": combined_index.pct_change().dropna(),
    "SPY": spy_index.pct_change().dropna()
}
plot_daily_return_histograms(daily_returns_strategies)

# 3. Plot Drawdown Curves
plot_drawdown_curves(strategies)

# 4. Plot Rolling Metrics for Combined Portfolio
plot_rolling_metrics(combined_index, window=60)

# 5. Plot Correlation Heatmap of Daily Returns
plot_correlation_heatmap(daily_returns_strategies)

# 6. Plot Bootstrap Sensitivity Histograms
bootstrap_results = bootstrap_sensitivity(combined_index, n_iter=500, sample_frac=0.5)
plot_bootstrap_histograms(bootstrap_results)

# 7. Plot Sector Weights
sector_weights = compute_sector_weights(price_data, etf_list, lookback_days=126)
plot_sector_weights(sector_weights)

# 8. Compute and Export Risk Metrics
metrics_list = []
for label, series in strategies.items():
    cum_ret, ann_ret, ann_vol, sharpe, max_dd = compute_risk_metrics(series, risk_free=risk_free_equity)
    metrics_list.append({
        "Strategy": label,
        "Cumulative Return (%)": cum_ret * 100,
        "Annualized Return (%)": ann_ret * 100,
        "Annualized Volatility (%)": ann_vol * 100,
        "Sharpe Ratio": sharpe,
        "Max Drawdown (%)": max_dd * 100
    })
metrics_df = pd.DataFrame(metrics_list)
print("\nRisk Metrics Comparison:")
print(metrics_df)
metrics_df.to_excel("portfolio_risk_metrics.xlsx", index=False)
print("Risk metrics have been written to portfolio_risk_metrics.xlsx")

# Output:
#   [****************      33%                       ]  4 of 12 completed
#   Fetching historical price data...

#   [*********************100%***********************]  12 of 12 completed

#   Running portfolio simulations...

#   Dynamic equity weight based on SPY volatility (12.43%): 0.70

#   Generating visualizations...

#   

#   Risk Metrics Comparison:

#                   Strategy  Cumulative Return (%)  Annualized Return (%)  \

#   0       Equity Portfolio             116.549237              14.641153   

#   1  Covered Call Strategy             162.870859              18.639180   

#   2     Combined Portfolio             134.059405              16.228439   

#   3         SPY Buy & Hold             113.663347              14.369482   

#   

#      Annualized Volatility (%)  Sharpe Ratio  Max Drawdown (%)  

#   0                  24.710571      0.511569        -32.613463  

#   1                  18.080073      0.920305        -20.609662  

#   2                  21.351087      0.666403        -28.973307  

#   3                  20.067729      0.616387        -33.717262  

#   Risk metrics have been written to portfolio_risk_metrics.xlsx

#   <Figure size 1200x700 with 1 Axes>
#   <Figure size 1400x800 with 4 Axes>
#   <Figure size 1200x700 with 1 Axes>
#   <Figure size 1200x700 with 2 Axes>
#   <Figure size 800x600 with 2 Axes>
#   <Figure size 1400x800 with 5 Axes>
#   <Figure size 1000x600 with 1 Axes>



================================================
File: notebooks/portfolio_risk_metrics.xlsx
================================================
[Non-text file]



================================================
File: old_scripts/bonds.py
================================================
# bonds.py

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pandas_datareader.data as web
from datetime import datetime
from config import Start_Date, End_Date

def get_bond_portfolio(start_date, end_date, T=0.25, plot_results=True):
    """
    Builds a bond "portfolio" based on roll-down valuation. It downloads Treasury 
    yields for maturities 2Y, 5Y, 10Y, 20Y, and 30Y from FRED, resamples the data 
    to quarterly snapshots, and then uses a roll-down model to compute the expected 
    annualized return for each bond over a holding period T (default: 0.25 years).
    
    For each quarter, it calculates the expected return on each bond using the formula:
         Expected Return = [ current_yield * maturity - y_new * (maturity - T) ] / T
    where y_new is obtained by linear interpolation on the current yield curve.
    
    Parameters:
        start_date (str): The start date (format 'YYYY-MM-DD').
        end_date (str): The end date (format 'YYYY-MM-DD').
        T (float): The holding period in years over which to roll down the yield curve (default 0.25 for a quarter).
        plot_results (bool): If True, plot the quarterly expected returns for each maturity.
        
    Returns:
        expected_returns_quarterly (pd.DataFrame): A DataFrame indexed by quarter with columns '2Y', '5Y', '10Y', '20Y', '30Y'
                                                   representing the computed expected annualized returns.
        overall_expected_return (float): A simple average expected annualized return across bonds and quarters.
    """
    # -------------------------------------------------
    # 1. DATA ACQUISITION: Download Treasury yields from FRED
    # -------------------------------------------------
    # FRED series for U.S. Treasury yields:
    # 'DGS2'   = 2-Year, 'DGS5'  = 5-Year, 'DGS10' = 10-Year,
    # 'DGS20'  = 20-Year, 'DGS30' = 30-Year.
    series = ['DGS2', 'DGS5', 'DGS10', 'DGS20', 'DGS30']
    yields_df = web.DataReader(series, 'fred', start_date, end_date)
    
    # Drop any days with missing data and rename columns for clarity.
    yields_df = yields_df.dropna()
    yields_df.columns = ['2Y', '5Y', '10Y', '20Y', '30Y']
    
    # -------------------------
    # 2. RESAMPLE THE DATA (unchanged)
    quarterly_yields = yields_df.resample('Q').last()

    # -------------------------
    # 3. DEFINE ROLL-DOWN MODEL (unchanged)
    def compute_expected_return(maturity, current_yield, maturities, yield_curve, T):
        new_maturity = maturity - T
        y_new = np.interp(new_maturity, maturities, yield_curve, left=yield_curve[0], right=yield_curve[-1])
        return (current_yield * maturity - y_new * (maturity - T)) / T

    maturities = np.array([2, 5, 10, 20, 30], dtype=float)

    # -------------------------
    # 4. COMPUTE EXPECTED RETURNS FOR EACH QUARTER
    expected_returns_quarterly = pd.DataFrame(index=quarterly_yields.index,
                                            columns=['2Y','5Y','10Y','20Y','30Y'])

    for date, row in quarterly_yields.iterrows():
        yield_curve = np.array([row['2Y'], row['5Y'], row['10Y'], row['20Y'], row['30Y']],
                            dtype=float) / 100.0
        for i, mat in enumerate(maturities):
            exp_ret = compute_expected_return(mat, yield_curve[i], maturities, yield_curve, T)
            expected_returns_quarterly.loc[date, f'{int(mat)}Y'] = exp_ret

    expected_returns_quarterly = expected_returns_quarterly.astype(float)

    print("Quarterly Expected Annualized Returns (based on roll-down valuation):")
    print(expected_returns_quarterly)

    # -------------------------
    # 5. VISUALIZATION (unchanged)
    if plot_results:
        plt.figure(figsize=(10, 6))
        for col in expected_returns_quarterly.columns:
            plt.plot(expected_returns_quarterly.index, expected_returns_quarterly[col],
                    marker='o', linestyle='-', label=f'{col} Bond')
        plt.xlabel('Quarter')
        plt.ylabel('Expected Annualized Return')
        plt.title('Quarterly Expected Annualized Returns by Bond Maturity')
        plt.legend()
        plt.show()

    # Compute overall expected annual return (simple average).
    overall_expected_return = expected_returns_quarterly.mean().mean()

    # --------------------------------------------------
    # NEW LOGIC: If the overall expected return is not profitable,
    # we assume bonds are not attractive and therefore the strategy remains in cash.
    if overall_expected_return <= 0:
        print("Bonds expected returns not profitable. Remaining in cash.")
        # Override all the expected return data to zero, reflecting a cash allocation.
        expected_returns_quarterly[:] = 0.0
        overall_expected_return = 0.0

    return expected_returns_quarterly, overall_expected_return

    # --------------------------------------------------
    # NEW LOGIC: If the overall expected return is not profitable,
    # we assume bonds are not attractive and therefore the strategy remains in cash.
    if overall_expected_return <= 0:
        print("Bonds expected returns not profitable. Remaining in cash.")
        # Override all the expected return data to zero, reflecting a cash allocation.
        expected_returns_quarterly[:] = 0.0
        overall_expected_return = 0.0

    return expected_returns_quarterly, overall_expected_return

# Allow this module to run standalone for testing.
if __name__ == "__main__":
    start_date = Start_Date
    end_date = End_Date
    expected_returns_quarterly, overall_expected_return = get_bond_portfolio(start_date, end_date, T=0.25, plot_results=True)
    
    print("\nOverall Expected Annual Return (average across bonds and quarters): {:.2f}%".format(overall_expected_return * 100))



================================================
File: old_scripts/config.py
================================================
Start_Date = "2019-01-01"
End_Date = "2025-01-01"


================================================
File: old_scripts/equities.py
================================================
# equities.py

import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
from config import Start_Date, End_Date

def get_equity_portfolio(start_date, end_date, risk_free_rate=0.02, plot_frontier=False):
    """
    Builds an equity portfolio based on U.S. sector ETFs using CAPM expected returns,
    with quarterly rebalancing. For each quarter, the function uses all available 
    data up to that rebalance date to compute CAPM betas, expected returns, and an 
    annualized covariance matrix. It then runs a Monte Carlo simulation (10,000 iterations) 
    to identify the optimal allocation (maximizing the Sharpe ratio) which is applied 
    for that quarter.
    
    In this version, instead of generating daily returns, the portfolio return is 
    computed for each quarter (by compounding the daily returns over the quarter).
    
    Additionally, if plot_frontier=True, the efficient frontier is plotted only for the first quarter.
    
    Finally, the function computes the quarterly returns and cumulative returns and also
    overlays the benchmark (SPY) quarterly cumulative returns on the final plot.
    
    Parameters:
        start_date (str): The start date (format 'YYYY-MM-DD').
        end_date (str): The end date (format 'YYYY-MM-DD').
        risk_free_rate (float): Annual risk-free rate assumption (default: 0.02).
        plot_frontier (bool): Whether to show the efficient frontier plot for the first quarter.
        
    Returns:
        equity_quarterly_returns (pd.Series): Quarterly returns of the equity portfolio.
        equity_cum_returns (pd.Series): Cumulative returns (quarterly compounding) of the equity portfolio.
        equity_expected_return (float): Time-weighted average expected annual return from CAPM estimates.
    """
    # Define sector ETFs and benchmark (SPY)
    sector_etfs = ['XLY',  # Consumer Discretionary
                   'XLP',  # Consumer Staples
                   'XLE',  # Energy
                   'XLF',  # Financials
                   'XLV',  # Health Care
                   'XLI',  # Industrials
                   'XLB',  # Materials
                   'XLRE', # Real Estate
                   'XLK',  # Technology
                   'XLU',  # Utilities
                   'XLC']  # Communication Services
    benchmark_ticker = 'SPY'
    
    # Download adjusted close prices.
    tickers = sector_etfs + [benchmark_ticker]
    price_data = yf.download(tickers, start=start_date, end=end_date, auto_adjust=True)['Close']
    price_data = price_data.dropna()
    
    # Calculate daily returns.
    daily_returns = price_data.pct_change().dropna()
    
    # Determine quarterly rebalancing dates using quarter start frequency.
    # These dates are the first trading day of each quarter.
    rebalance_dates = daily_returns.resample('QS').first().index
    rebalance_dates = rebalance_dates[rebalance_dates >= daily_returns.index[0]]
    
    quarterly_returns_list = []  # to store one return per quarter
    exp_ret_list = []            # list of quarter CAPM expected return estimates (averaged over ETFs)
    weight_records = []          # record optimal weights by quarter
    
    for i, rebalance_date in enumerate(rebalance_dates):
        # Calibration period: all data up to and including the current rebalance date.
        calib_data = daily_returns.loc[:rebalance_date]
        etf_calib = calib_data[sector_etfs]
        bench_calib = calib_data[benchmark_ticker]
        
        # Compute annualized benchmark return using calibration data.
        avg_daily_bench = bench_calib.mean()
        annual_market_return = (1 + avg_daily_bench)**252 - 1
        
        # Compute CAPM beta and expected annual returns for each ETF.
        betas = {}
        expected_returns = {}
        for etf in sector_etfs:
            cov = np.cov(etf_calib[etf], bench_calib)[0, 1]
            var = bench_calib.var()
            beta = cov / var if var != 0 else 0
            betas[etf] = beta
            expected_returns[etf] = risk_free_rate + beta * (annual_market_return - risk_free_rate)
        exp_ret_series = pd.Series(expected_returns)
        exp_ret_list.append(exp_ret_series.mean())
        
        # Compute the annualized covariance matrix.
        cov_daily = etf_calib.cov()
        cov_matrix = cov_daily * 252
        
        # Monte Carlo simulation for optimal portfolio allocation.
        num_portfolios = 10000
        results = []
        num_assets = len(sector_etfs)
        np.random.seed(42)
        for _ in range(num_portfolios):
            weights = np.random.random(num_assets)
            weights /= np.sum(weights)
            port_return = np.sum(exp_ret_series.values * weights)
            port_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
            sharpe_ratio = (port_return - risk_free_rate) / port_volatility if port_volatility != 0 else 0
            results.append({
                'Return': port_return,
                'Volatility': port_volatility,
                'Sharpe': sharpe_ratio,
                'Weights': weights
            })
        results_df = pd.DataFrame(results)
        max_sharpe_idx = results_df['Sharpe'].idxmax()
        max_sharpe_portfolio = results_df.loc[max_sharpe_idx]
        optimal_weights = pd.Series(max_sharpe_portfolio['Weights'], index=sector_etfs)
        weight_records.append((rebalance_date, optimal_weights))
        
        # Plot the efficient frontier for the first quarter if requested (optional).
        '''
        if plot_frontier and i == 0:
            plt.figure(figsize=(10, 6))
            sc = plt.scatter(results_df['Volatility'], results_df['Return'], 
                             c=results_df['Sharpe'], cmap='viridis', marker='o', s=10, alpha=0.5)
            plt.colorbar(sc, label='Sharpe Ratio')
            plt.scatter(max_sharpe_portfolio['Volatility'], max_sharpe_portfolio['Return'], 
                        color='red', marker='*', s=500, label='Max Sharpe')
            plt.xlabel('Annualized Volatility')
            plt.ylabel('Annualized Return')
            plt.title(f'Efficient Frontier (Rebalance: {rebalance_date.date()})')
            plt.legend()
            plt.show()
        '''
        # Determine the period over which to calculate the portfolio return.
        # Here, we want to do the calculation at the end of the period (quarter-end) before the new one starts.
        if i < len(rebalance_dates) - 1:
            # Get all trading days from the current rebalance date until the next quarter's start.
            period_data = daily_returns.loc[rebalance_date:rebalance_dates[i+1]]
            # The period_end is the last trading day in this interval.
            period_end = period_data.index[-1]
        else:
            period_end = daily_returns.index[-1]
        
        # Extract daily returns for the current quarter period.
        quarter_data = daily_returns.loc[rebalance_date:period_end, sector_etfs]
        # Compute the portfolio daily returns for the quarter.
        portfolio_daily = (quarter_data * optimal_weights).sum(axis=1)
        # Compute the quarterly return by compounding daily returns.
        quarter_return = (1 + portfolio_daily).prod() - 1
        # The quarter return is assigned the timestamp of the period_end.
        quarterly_returns_list.append(pd.Series(quarter_return, index=[period_end]))
    
    # Concatenate quarterly returns into one Series and compute cumulative returns.
    equity_quarterly_returns = pd.concat(quarterly_returns_list).sort_index()
    equity_cum_returns = (1 + equity_quarterly_returns).cumprod()
    
    # Compute time-weighted average expected annual return (weighted by number of days in each quarter).
    quarter_lengths = [
        len(daily_returns.loc[rebalance_dates[i]:rebalance_dates[i+1]])
        if i < len(rebalance_dates)-1 else len(daily_returns.loc[rebalance_dates[i]:])
        for i in range(len(rebalance_dates))
    ]
    weighted_exp_return = np.average(exp_ret_list, weights=quarter_lengths)
    
    # Compute benchmark (SPY) quarterly returns.
    spy_data = price_data[benchmark_ticker]
    spy_quarterly = spy_data.resample('Q').last().pct_change().dropna()
    spy_cum_returns = (1 + spy_quarterly).cumprod()
    
    return equity_quarterly_returns, equity_cum_returns, weighted_exp_return

# Allow the module to run standalone for testing.
if __name__ == "__main__":
    start_date = Start_Date
    end_date = End_Date
    risk_free_rate = 0.02
    
    eq_qtr, eq_cum, eq_exp_return = get_equity_portfolio(start_date, end_date, risk_free_rate, plot_frontier=False)
    
    print("\nEquity Portfolio Quarterly Testing:")
    print("Final Cumulative Return: {:.2f}".format(eq_cum.iloc[-1]))
    print("Time-Weighted Average Expected Annual Return: {:.2f}%".format(eq_exp_return * 100))
    
    plt.figure(figsize=(10,6))
    plt.plot(eq_cum.index, eq_cum, label="Equity Portfolio Cumulative Returns")
    plt.xlabel("Date")
    plt.ylabel("Cumulative Return")
    plt.title("Equity Portfolio (Quarterly Rebalancing) Backtest")
    plt.legend()
    plt.show()



================================================
File: old_scripts/options.py
================================================
# options.py

import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
from scipy.stats import norm
import warnings

warnings.filterwarnings('ignore')

# Parameters for simulation
Start_Date = "2019-01-01"   # Use a longer period to capture volatility.
End_Date = "2024-12-31"
risk_free_rate = 0.01       # Annual risk-free rate (1%).
shares_per_contract = 100   # Number of shares per option contract.
strike_buffer = 0.05        # Call strike is 5% above the current price.
option_term_days = 30       # Option expires 30 days from sale.
etf_list = ['XLY', 'XLP', 'XLE', 'XLF', 'XLV',
            'XLI', 'XLB', 'XLRE', 'XLK', 'XLU', 'XLC']

# ---------------------------
# Step 1: Define Black-Scholes Function
# ---------------------------
def black_scholes_call(S, K, T, r, sigma):
    """
    Calculate the Black-Scholes price for a European call option.
    
    Parameters:
      S (float): Spot price of the underlying asset.
      K (float): Strike price.
      T (float): Time to expiration in years.
      r (float): Annual risk-free rate.
      sigma (float): Annualized volatility.
    
    Returns:
      float: Theoretical price of the call option.
    """
    if T <= 0 or sigma <= 0:
        return max(S - K, 0)
    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))
    d2 = d1 - sigma * np.sqrt(T)
    call_price = S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)
    return call_price

# ---------------------------
# Step 2: Simulate Covered Call for a Single ETF
# ---------------------------
def simulate_covered_call_for_etf(ticker, start_date, end_date):
    """
    Run a daily simulation of a covered call strategy for a single ETF.
    
    Parameters:
      ticker (str): ETF ticker symbol.
      start_date (str): Start date for data download.
      end_date (str): End date for data download.
    
    Returns:
      pd.DataFrame: Daily portfolio value for the ETF.
    """
    # Download historical data for the given ticker.
    data = yf.download(ticker, start=start_date, end=end_date, progress=False)
    if data.empty:
        raise ValueError(f"No data downloaded for {ticker}")
    # Use the 'Close' prices.
    price_data = data["Close"].dropna()
    # Create a DataFrame from the Series and force the column name to 'Price'.
    df = pd.DataFrame(price_data)
    df.columns = ['Price']
    # Calculate log returns.
    df['Returns'] = np.log(df['Price'] / df['Price'].shift(1))
    # Calculate rolling volatility (30-day window, annualized).
    window_size = 30
    df['Volatility'] = df['Returns'].rolling(window=window_size).std() * np.sqrt(252)
    df.dropna(inplace=True)
    # Identify option selling dates: first trading day of each month.
    monthly_dates = df.resample('MS').first().index

    # === Modification: Initialize as if you already hold the underlying shares ===
    # In a covered call, you already own the stock. So start with one contract's worth:
    shares = shares_per_contract  # Already holding shares.
    cash = 0.0  # No cash initially.
    
    portfolio_value = []
    dates = []
    positions = []  # Option positions.

    for current_date in df.index:
        S = df.loc[current_date, 'Price']
        sigma = df.loc[current_date, 'Volatility']
        # Update portfolio value (should be nonzero after the first day).
        portfolio_val = cash + shares * S
        dates.append(current_date)
        portfolio_value.append(portfolio_val)
        
        # Check if any sold option has expired.
        positions_to_remove = []
        for pos in positions:
            if current_date >= pos['expiration_date']:
                K = pos['K']
                # If S > K, the option is exercised (shares are called away).
                if S > K:
                    cash += shares * K
                    shares = 0
                positions_to_remove.append(pos)
        for pos in positions_to_remove:
            positions.remove(pos)
        
        # On month start, sell a new call.
        if current_date in monthly_dates:
            # If not holding shares (because they were called away), buy a contract's worth.
            if shares == 0:
                shares = shares_per_contract
                cash -= shares * S
            # Define option parameters.
            T = option_term_days / 252.0
            K = S * (1 + strike_buffer)
            call_premium = black_scholes_call(S, K, T, risk_free_rate, sigma) * shares_per_contract
            positions.append({
                'expiration_date': current_date + pd.Timedelta(days=option_term_days),
                'K': K
            })
            cash += call_premium

    result_df = pd.DataFrame({'Date': dates, 'Portfolio Value': portfolio_value})
    result_df.set_index('Date', inplace=True)
    return result_df

# ---------------------------
# Step 3: Simulate Portfolio Covered Call Strategy
# ---------------------------
def simulate_covered_calls_portfolio(etf_list, start_date, end_date):
    """
    Run the covered call simulation for each ETF in the list and combine them with equal weighting.
    
    Parameters:
      etf_list (list): List of ETF ticker symbols.
      start_date (str): Start date for simulation.
      end_date (str): End date for simulation.
      
    Returns:
      pd.Series: Combined portfolio value time series.
    """
    portfolio_dfs = {}
    for ticker in etf_list:
        try:
            df = simulate_covered_call_for_etf(ticker, start_date, end_date)
            portfolio_dfs[ticker] = df['Portfolio Value']
            print(f"Simulated {ticker}: {df['Portfolio Value'].iloc[0]:.2f} -> {df['Portfolio Value'].iloc[-1]:.2f}")
        except Exception as e:
            print(f"Error simulating {ticker}: {e}")
    if not portfolio_dfs:
        raise ValueError("No ETF data available for simulation.")
    # Combine individual ETF portfolio values by aligning on dates.
    combined_df = pd.concat(portfolio_dfs, axis=1)
    combined_portfolio = combined_df.mean(axis=1)
    return combined_portfolio

# ---------------------------
# Step 4: Run Simulation and Visualize Results
# ---------------------------
if __name__ == "__main__":
    combined_portfolio = simulate_covered_calls_portfolio(etf_list, Start_Date, End_Date)
    
    # Calculate buy-and-hold portfolio (equal weight across ETFs).
    price_data_all = yf.download(etf_list, start=Start_Date, end=End_Date, auto_adjust=True)['Close']
    buy_hold = price_data_all.mean(axis=1)
    initial_value = buy_hold.iloc[0]
    buy_hold_portfolio = buy_hold / initial_value  # Normalized time series.
    
    # Normalize the combined portfolio time series (starting at 1).
    combined_norm = combined_portfolio / combined_portfolio.iloc[0]
    
    plt.figure(figsize=(14, 7))
    plt.plot(combined_norm.index, combined_norm.values, label='Covered Call Strategy')
    plt.plot(buy_hold_portfolio.index, buy_hold_portfolio.values, label='Buy & Hold Strategy')
    plt.xlabel('Date')
    plt.ylabel('Normalized Portfolio Value')
    plt.title('Covered Call Strategy vs. Buy & Hold Strategy')
    plt.legend()
    plt.grid(True)
    plt.show()
    
    covered_call_return = (combined_norm.iloc[-1] - 1) * 100
    buy_hold_return = (buy_hold_portfolio.iloc[-1] - 1) * 100
    print(f"Total Return of Covered Call Strategy: {covered_call_return:.2f}%")
    print(f"Total Return of Buy & Hold Strategy: {buy_hold_return:.2f}%")




================================================
File: scripts/portfolio.py
================================================
import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
from scipy.stats import norm
from datetime import timedelta
# PyPortfolioOpt imports:
from pypfopt import EfficientFrontier, risk_models, expected_returns
import scipy.optimize as opt

# --- Configuration ---
Start_Date = "2019-06-01"
End_Date   = "2024-12-31"
risk_free_equity = 0.02      # For CAPM & Sharpe (annual)
risk_free_option = 0.01      # For Black-Scholes pricing (annual)
shares_per_contract = 100
transaction_cost = 0.001     # 0.1% per trade cost

# Parameters for covered call enhancements:
# (Using delta-targeting, the target delta is our key input)
target_delta = 0.3          # Initial target delta (to be optimized)
threshold_vol_option = 0.25  # Initial threshold volatility (annual) for option term decision
short_option_term = 60       # Option term (days) in high volatility periods
long_option_term = 90        # Option term (days) in low volatility periods

# Dynamic weight allocation parameters (for combined portfolio)
high_equity_weight = 0.70    # When SPY volatility is low
low_equity_weight = 0.45     # When SPY volatility is high
vol_threshold = 0.25         # SPY volatility threshold (annual)

# Same ETF list and market benchmark
etf_list = ['XLY', 'XLP', 'XLE', 'XLF', 'XLV',
            'XLI', 'XLB', 'XLRE', 'XLK', 'XLU', 'XLC']
benchmark_ticker = 'SPY'

# --- Helper Functions ---

def compute_dynamic_base_buffer(S, sigma, T, r, target_yield=0.015, min_b=0.01, max_b=0.15, step=0.005):
    """
    Compute a dynamic base strike buffer such that the theoretical option premium yield 
    is as close as possible to the target_yield.
    """
    best_b = min_b
    best_diff = float('inf')
    for b in np.arange(min_b, max_b + step, step):
        K = S * (1 + b)
        premium = black_scholes_call(S, K, T, r, sigma)
        yield_est = premium / (S * shares_per_contract)
        diff = abs(yield_est - target_yield)
        if diff < best_diff:
            best_diff = diff
            best_b = b
    return best_b

def delta_targeted_strike(S, T, r, sigma, target_delta=target_delta):
    """
    Compute the call strike K such that under the Black-Scholes model the call delta is equal to target_delta.
    
    K = S * exp(-σ√T * N⁻¹(target_delta) + (r + 0.5σ²)T)
    """
    d_target = norm.ppf(target_delta)
    K = S * np.exp(-sigma * np.sqrt(T) * d_target + (r + 0.5 * sigma**2)*T)
    return K

def dynamic_option_term(sigma, threshold=threshold_vol_option, short_term=short_option_term, long_term=long_option_term):
    """
    Choose option term in days based on current annualized volatility.
    """
    return long_term if sigma < threshold else short_term

def dynamic_weight_allocation(current_vol, low=low_equity_weight, high=high_equity_weight, threshold=vol_threshold):
    """
    Adjust overall equity allocation based on SPY's recent annualized volatility.
    """
    return low if current_vol >= threshold else high

def compute_sector_weights(price_data, etfs, lookback_days=126):
    """
    Compute weights for each ETF based on trailing 6-month performance.
    Negative returns are clipped to zero.
    """
    last_date = price_data.index.max()
    start_date = last_date - pd.Timedelta(days=lookback_days)
    trailing_return = price_data.loc[start_date:last_date, etfs].iloc[-1] / price_data.loc[start_date:last_date, etfs].iloc[0] - 1
    trailing_return = trailing_return.clip(lower=0)
    if trailing_return.sum() == 0:
        weights = pd.Series(1/len(etfs), index=etfs)
    else:
        weights = trailing_return / trailing_return.sum()
    return weights

# --- Black-Scholes Call Option Pricing ---
def black_scholes_call(S, K, T, r, sigma):
    """
    Calculate the Black-Scholes price for a European call option.
    """
    if T <= 0 or sigma <= 0:
        return max(S - K, 0.0)
    d1 = (np.log(S / K) + (r + 0.5 * sigma**2)*T) / (sigma * np.sqrt(T))
    d2 = d1 - sigma * np.sqrt(T)
    return S * norm.cdf(d1) - K * np.exp(-r*T) * norm.cdf(d2)

# --- Covered Call Simulation for a Single ETF ---
def simulate_covered_call_for_etf(ticker, price_series):
    """
    Simulate daily portfolio values for a covered call strategy on one ETF.
    Uses delta-targeted strike selection and a dynamic option term.
    """
    df = pd.DataFrame({'Price': price_series.dropna()})
    df['LogReturn'] = np.log(df['Price'] / df['Price'].shift(1))
    df['Volatility'] = df['LogReturn'].rolling(window=30).std() * np.sqrt(252)
    df.dropna(inplace=True)
    
    # Monthly option sale dates: first trading day of each month.
    monthly_dates = df.resample('MS').first().index
    monthly_dates = [d for d in monthly_dates if d in df.index]
    
    shares = shares_per_contract
    cash = 0.0
    portfolio_values = []
    dates = []
    active_calls = []  # Each call: {'strike': K, 'expiration': date}
    
    for current_date in df.index:
        S = df.at[current_date, 'Price']
        sigma = df.at[current_date, 'Volatility']
        portfolio_val = cash + shares * S
        dates.append(current_date)
        portfolio_values.append(portfolio_val)
        
        # Check expiration of active options.
        for pos in list(active_calls):
            if current_date >= pos['expiration']:
                K = pos['strike']
                if S > K and shares > 0:
                    cash += shares * K
                    shares = 0
                active_calls.remove(pos)
        
        if current_date in monthly_dates:
            if shares == 0:
                shares = shares_per_contract
                cash -= shares * S
                cash -= (shares * S) * transaction_cost
            # Determine option term dynamically.
            opt_term = dynamic_option_term(sigma)
            T = opt_term / 252.0
            # Use delta-targeted strike selection.
            K = delta_targeted_strike(S, T, risk_free_option, sigma, target_delta=target_delta)
            premium = black_scholes_call(S, K, T, risk_free_option, sigma) * shares_per_contract
            cash += premium
            cash -= (shares * S) * transaction_cost
            expiration_date = current_date + pd.Timedelta(days=opt_term)
            active_calls.append({'strike': K, 'expiration': expiration_date})
    
    return pd.Series(portfolio_values, index=dates)

# --- Covered Call Portfolio ---
def simulate_covered_calls_portfolio(etfs, price_data):
    """
    Run the covered call simulation for each ETF and combine the results using performance-based weights.
    Returns a normalized daily series.
    """
    portfolios = {}
    for ticker in etfs:
        try:
            prices = price_data[ticker]
            portfolios[ticker] = simulate_covered_call_for_etf(ticker, prices)
        except Exception as e:
            print(f"Warning: Simulation for {ticker} failed: {e}")
    if not portfolios:
        raise ValueError("No ETF data available for covered call simulation.")
    sector_weights = compute_sector_weights(price_data, etfs, lookback_days=126)
    combined_df = pd.DataFrame(portfolios).sort_index().ffill()
    weighted_portfolio = combined_df.multiply(sector_weights, axis=1).sum(axis=1)
    normalized = weighted_portfolio / weighted_portfolio.iloc[0]
    return normalized

# --- Equity Portfolio Simulation (Using PyPortfolioOpt) ---
def simulate_equity_portfolio(etfs, benchmark, price_data, calib_years=2):
    """
    Simulate a quarterly-rebalanced equity portfolio using a rolling calibration window and PyPortfolioOpt.
    Returns a normalized daily series.
    """
    daily_returns = price_data.pct_change().dropna()
    rebalance_dates = daily_returns.resample('QS').first().index
    rebalance_dates = [d for d in rebalance_dates if d >= daily_returns.index[0]]
    
    dates = []
    values = []
    current_value = 1.0
    
    for i, rebalance_date in enumerate(rebalance_dates):
        if rebalance_date > daily_returns.index[-1]:
            break
        window_start = rebalance_date - pd.DateOffset(years=calib_years)
        calib_data = daily_returns.loc[window_start:rebalance_date]
        mu = expected_returns.mean_historical_return(price_data.loc[window_start:rebalance_date], frequency=252)
        Sigma = risk_models.sample_cov(price_data.loc[window_start:rebalance_date], frequency=252)
        ef = EfficientFrontier(mu, Sigma, weight_bounds=(0, 1))
        ef.max_sharpe(risk_free_equity)
        weights = ef.clean_weights()
        optimal_weights = pd.Series(weights)
        if i > 0:
            current_value *= (1 - transaction_cost)
        
        if i < len(rebalance_dates) - 1:
            next_start = rebalance_dates[i + 1]
            period_idx = daily_returns.index[daily_returns.index < next_start]
            period_end = period_idx[-1] if len(period_idx) > 0 else daily_returns.index[-1]
        else:
            period_end = daily_returns.index[-1]
        
        period_returns = daily_returns.loc[rebalance_date:period_end, etfs]
        if rebalance_date not in period_returns.index:
            dates.append(rebalance_date)
            values.append(current_value)
        for day in period_returns.index:
            if day == rebalance_date:
                dates.append(day)
                values.append(current_value)
            daily_ret = np.dot(period_returns.loc[day, etfs], optimal_weights[etfs])
            current_value *= (1 + daily_ret)
            dates.append(day)
            values.append(current_value)
    
    equity_portfolio = pd.Series(values, index=dates)
    equity_portfolio = equity_portfolio[~equity_portfolio.index.duplicated(keep='first')]
    equity_index = equity_portfolio / equity_portfolio.iloc[0]
    return equity_index

# --- Bootstrap Sensitivity Analysis ---
def bootstrap_sensitivity(index_series, n_iter=1000, sample_frac=0.5):
    """
    Perform bootstrap resampling on the portfolio's daily returns to assess sensitivity.
    Returns a DataFrame with bootstrap distributions of risk metrics.
    """
    returns = index_series.pct_change().dropna()
    metrics_list = []
    for _ in range(n_iter):
        sample = returns.sample(frac=sample_frac, replace=True)
        sample_series = (1 + sample).cumprod()
        metrics_list.append(compute_risk_metrics(sample_series))
    bootstrap_df = pd.DataFrame(metrics_list, columns=["Cumulative Return", "Annual Return", "Volatility", "Sharpe", "Max Drawdown"])
    return bootstrap_df

# --- Compute Risk Metrics ---
def compute_risk_metrics(index_series, risk_free=0.02):
    """
    Compute risk metrics for a normalized index series.
    Returns cumulative return, annualized return, annual volatility, Sharpe ratio, and max drawdown.
    """
    returns = index_series.pct_change().dropna()
    cumulative_return = index_series.iloc[-1] / index_series.iloc[0] - 1
    annual_factor = 252
    annual_return = (index_series.iloc[-1] / index_series.iloc[0])**(annual_factor/len(index_series)) - 1
    ann_vol = returns.std() * np.sqrt(annual_factor)
    sharpe = (annual_return - risk_free) / (ann_vol if ann_vol != 0 else np.nan)
    running_max = index_series.cummax()
    drawdown = (index_series - running_max) / running_max
    max_drawdown = drawdown.min()
    return cumulative_return, annual_return, ann_vol, sharpe, max_drawdown

# --- Optimizer for Parameters ---
def objective(params, price_data):
    """
    Objective function to be minimized (negative Sharpe ratio) given a vector of parameters.
    Parameters vector:
      params[0]: target_delta
      params[1]: threshold_vol_option
      params[2]: short_option_term (days)
      params[3]: long_option_term (days)
      params[4]: high_equity_weight
      params[5]: low_equity_weight
      params[6]: vol_threshold
    """
    global target_delta, threshold_vol_option, short_option_term, long_option_term, high_equity_weight, low_equity_weight, vol_threshold
    target_delta = params[0]
    threshold_vol_option = params[1]
    short_option_term = int(round(params[2]))
    long_option_term = int(round(params[3]))
    high_equity_weight = params[4]
    low_equity_weight = params[5]
    vol_threshold = params[6]
    
    try:
        equity_index = simulate_equity_portfolio(etf_list, benchmark_ticker, price_data)
        covered_call_index = simulate_covered_calls_portfolio(etf_list, price_data)
    
        common_start = max(equity_index.index.min(), covered_call_index.index.min())
        full_dates = pd.date_range(start=common_start, end=price_data.index.max(), freq='B')
    
        equity_index_full = equity_index.reindex(full_dates).ffill().bfill()
        covered_call_index_full = covered_call_index.reindex(full_dates).ffill().bfill()
    
        equity_daily_ret = equity_index_full.pct_change().fillna(0)
        option_daily_ret = covered_call_index_full.pct_change().fillna(0)
    
        spy_prices = price_data[benchmark_ticker]
        spy_returns = spy_prices.pct_change().dropna()
        spy_vol = spy_returns.rolling(window=30).std().iloc[-1] * np.sqrt(252)
        dyn_equity_weight = dynamic_weight_allocation(spy_vol)
    
        combined_daily_ret = dyn_equity_weight * equity_daily_ret + (1 - dyn_equity_weight) * option_daily_ret
        combined_index = (1 + combined_daily_ret).cumprod()
    
        _, _, _, sharpe, _ = compute_risk_metrics(combined_index, risk_free=risk_free_equity)
    except Exception as e:
        sharpe = -100  # Penalize if simulation fails
    
    if np.isnan(sharpe):
        return 1000
    return -sharpe  # We want to maximize Sharpe, so minimize negative Sharpe

# Define bounds for each parameter
bounds = [
    (0.25, 0.55),    # target_delta
    (0.15, 0.30),    # threshold_vol_option
    (20, 90),        # short_option_term (days)
    (30, 120),       # long_option_term (days)
    (0.60, 0.80),    # high_equity_weight
    (0.10, 0.50),    # low_equity_weight
    (0.20, 0.40)     # vol_threshold
]

# --- Main Execution ---
if __name__ == "__main__":
    # Download historical price data.
    all_tickers = etf_list + [benchmark_ticker]
    price_data = yf.download(all_tickers, start=Start_Date, end=End_Date, auto_adjust=True)['Close']
    price_data.dropna(inplace=True)
    
    # Run current simulations and print risk metrics.
    equity_index = simulate_equity_portfolio(etf_list, benchmark_ticker, price_data)
    covered_call_index = simulate_covered_calls_portfolio(etf_list, price_data)
    
    common_start = max(equity_index.index.min(), covered_call_index.index.min())
    full_dates = pd.date_range(start=common_start, end=price_data.index.max(), freq='B')
    
    equity_index_full = equity_index.reindex(full_dates).ffill().bfill()
    covered_call_index_full = covered_call_index.reindex(full_dates).ffill().bfill()
    equity_daily_ret = equity_index_full.pct_change().fillna(0)
    option_daily_ret = covered_call_index_full.pct_change().fillna(0)
    
    spy_prices = price_data[benchmark_ticker]
    spy_returns = spy_prices.pct_change().dropna()
    spy_vol = spy_returns.rolling(window=30).std().iloc[-1] * np.sqrt(252)
    dyn_equity_weight = dynamic_weight_allocation(spy_vol)
    print(f"Dynamic equity weight based on SPY volatility ({spy_vol:.2%}): {dyn_equity_weight:.2f}")
    
    combined_daily_ret = dyn_equity_weight * equity_daily_ret + (1 - dyn_equity_weight) * option_daily_ret
    combined_index = (1 + combined_daily_ret).cumprod()
    spy_index = (price_data[benchmark_ticker] / price_data[benchmark_ticker].iloc[0]).reindex(full_dates).ffill().bfill()
    
    plt.figure(figsize=(10,6))
    plt.plot(equity_index_full.index, equity_index_full.values, label='Equity Portfolio')
    plt.plot(covered_call_index_full.index, covered_call_index_full.values, label='Covered Call Strategy')
    plt.plot(combined_index.index, combined_index.values, label='Combined Portfolio')
    plt.plot(spy_index.index, spy_index.values, label='SPY Buy & Hold', linestyle='--')
    plt.title('Cumulative Returns Comparison')
    plt.xlabel('Date')
    plt.ylabel('Normalized Value (Start = 1.0)')
    plt.legend(loc='best')
    plt.grid(True)
    plt.savefig('cumulative_returns_comparison.png')
    plt.show()
    
    strategies = {
        'Equity Portfolio': equity_index_full,
        'Covered Call Strategy': covered_call_index_full,
        'Combined Portfolio': combined_index,
        'SPY Buy & Hold': spy_index
    }
    metrics = []
    for name, series in strategies.items():
        cum_ret, ann_ret, ann_vol, sharpe, max_dd = compute_risk_metrics(series, risk_free=risk_free_equity)
        metrics.append({
            "Strategy": name,
            "Cumulative Return (%)": cum_ret * 100,
            "Annualized Return (%)": ann_ret * 100,
            "Annualized Volatility (%)": ann_vol * 100,
            "Sharpe Ratio": sharpe,
            "Max Drawdown (%)": max_dd * 100
        })
    metrics_df = pd.DataFrame(metrics)
    print("\nRisk Metrics Comparison:")
    print(metrics_df)
    excel_filename = "portfolio_risk_metrics.xlsx"
    metrics_df.to_excel(excel_filename, index=False)
    print(f"\nRisk metrics have been written to {excel_filename}")
    
    bootstrap_results = bootstrap_sensitivity(combined_index, n_iter=500, sample_frac=0.5)
    print("\nBootstrap Sensitivity Analysis (first 5 rows):")
    print(bootstrap_results.head())
    
    # --- Optimization ---
    # Use differential evolution to optimize the covered call parameters (and dynamic weight allocation parameters)
    '''
    result = opt.differential_evolution(objective, bounds, args=(price_data,), maxiter=50, tol=0.01, disp=True)
    print("\nOptimized Parameters:")
    print("target_delta:", result.x[0])
    print("threshold_vol_option:", result.x[1])
    print("short_option_term:", int(round(result.x[2])))
    print("long_option_term:", int(round(result.x[3])))
    print("high_equity_weight:", result.x[4])
    print("low_equity_weight:", result.x[5])
    print("vol_threshold:", result.x[6])
    print("Max Sharpe achieved:", -result.fun)
    '''


================================================
File: scripts/visuals.py
================================================
# visuals.py

import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
import seaborn as sns

# Import portfolio simulation functions from your portfolio.py script
from portfolio import (
    simulate_equity_portfolio,
    simulate_covered_calls_portfolio,
    compute_risk_metrics,
    bootstrap_sensitivity,
    compute_sector_weights,
    dynamic_weight_allocation,
    risk_free_equity
)

# --- Configuration (should match portfolio.py) ---
Start_Date = "2019-06-01"
End_Date   = "2024-12-31"
benchmark_ticker = 'SPY'
etf_list = ['XLY', 'XLP', 'XLE', 'XLF', 'XLV',
            'XLI', 'XLB', 'XLRE', 'XLK', 'XLU', 'XLC']

# --- Data Acquisition ---
print("Fetching historical price data...")
all_tickers = etf_list + [benchmark_ticker]
price_data = yf.download(all_tickers, start=Start_Date, end=End_Date, auto_adjust=True)['Close']
price_data.dropna(inplace=True)

# --- Run Portfolio Simulations ---
print("Running portfolio simulations...")
equity_index = simulate_equity_portfolio(etf_list, benchmark_ticker, price_data)
covered_call_index = simulate_covered_calls_portfolio(etf_list, price_data)

# Define common date range from the later of the two series' first dates.
common_start = max(equity_index.index.min(), covered_call_index.index.min())
full_dates = pd.date_range(start=common_start, end=price_data.index.max(), freq='B')

equity_index_full = equity_index.reindex(full_dates).ffill().bfill()
covered_call_index_full = covered_call_index.reindex(full_dates).ffill().bfill()

# Compute daily returns for each strategy.
equity_daily_ret = equity_index_full.pct_change().fillna(0)
option_daily_ret = covered_call_index_full.pct_change().fillna(0)

# Prepare SPY normalized series on the same date range.
spy_index = price_data[benchmark_ticker].reindex(full_dates).ffill().bfill()
spy_index = spy_index / spy_index.iloc[0]

# Compute dynamic equity allocation using SPY volatility.
spy_returns = spy_index.pct_change().dropna()
spy_vol = spy_returns.rolling(window=30).std().iloc[-1] * np.sqrt(252)
dyn_equity_weight = dynamic_weight_allocation(spy_vol)
print(f"Dynamic equity weight based on SPY volatility ({spy_vol:.2%}): {dyn_equity_weight:.2f}")

# Combine equity and covered call strategies using the dynamic equity weight.
combined_daily_ret = dyn_equity_weight * equity_daily_ret + (1 - dyn_equity_weight) * option_daily_ret
combined_index = (1 + combined_daily_ret).cumprod()

# Create a dictionary with strategy series.
strategies = {
    "Equity Portfolio": equity_index_full,
    "Covered Call Strategy": covered_call_index_full,
    "Combined Portfolio": combined_index,
    "SPY Buy & Hold": spy_index
}

# --- Visualization Functions ---

def plot_cumulative_returns(strategy_dict):
    plt.figure(figsize=(12, 7))
    for label, series in strategy_dict.items():
        plt.plot(series.index, series.values, label=label)
    plt.title("Cumulative Returns Comparison")
    plt.xlabel("Date")
    plt.ylabel("Normalized Value (Base = 1.0)")
    plt.legend(loc="best")
    plt.grid(True)
    plt.savefig("output/cumulative_returns.png")

def plot_daily_return_histograms(daily_returns_dict):
    """Plot histograms for daily returns for each strategy, filtering out non-finite values."""
    plt.figure(figsize=(14, 8))
    for i, (label, daily_ret) in enumerate(daily_returns_dict.items()):
        # Filter out any non-finite values
        daily_ret = daily_ret[np.isfinite(daily_ret)]
        if daily_ret.empty:
            print(f"Warning: {label} daily returns are empty or contain no finite values.")
            continue
        plt.subplot(2, 2, i+1)
        plt.hist(daily_ret, bins=50, alpha=0.75, color="skyblue")
        plt.title(f"Daily Returns: {label}")
        plt.xlabel("Return")
        plt.ylabel("Frequency")
    plt.tight_layout()
    plt.savefig("output/daily_return_histograms.png")

def plot_drawdown_curves(strategy_dict):
    plt.figure(figsize=(12, 7))
    for label, series in strategy_dict.items():
        running_max = series.cummax()
        drawdown = (series - running_max) / running_max
        plt.plot(drawdown.index, drawdown.values, label=label)
    plt.title("Drawdown Curves")
    plt.xlabel("Date")
    plt.ylabel("Drawdown")
    plt.legend(loc="best")
    plt.grid(True)
    plt.savefig("output/drawdown_curves.png")

def plot_rolling_metrics(series, window=60):
    daily_ret = series.pct_change().dropna()
    rolling_vol = daily_ret.rolling(window=window).std() * np.sqrt(252)
    # Compute rolling cumulative return over the window
    rolling_return = (1 + daily_ret).rolling(window=window).apply(np.prod, raw=True) - 1
    rolling_sharpe = (rolling_return - risk_free_equity) / rolling_vol
    fig, ax1 = plt.subplots(figsize=(12, 7))
    ax1.plot(rolling_vol.index, rolling_vol, color="blue", label="Rolling Volatility")
    ax1.set_ylabel("Volatility", color="blue")
    ax1.tick_params(axis="y", labelcolor="blue")
    ax2 = ax1.twinx()
    ax2.plot(rolling_sharpe.index, rolling_sharpe, color="red", label="Rolling Sharpe")
    ax2.set_ylabel("Sharpe Ratio", color="red")
    ax2.tick_params(axis="y", labelcolor="red")
    plt.title(f"Rolling {window}-Day Volatility & Sharpe Ratio (Combined Portfolio)")
    fig.legend(loc="upper right", bbox_to_anchor=(1,1))
    plt.savefig("output/rolling_metrics.png")

def plot_correlation_heatmap(daily_returns_dict):
    data = {}
    for label, ret in daily_returns_dict.items():
        data[label] = ret
    returns_df = pd.DataFrame(data)
    corr_matrix = returns_df.corr()
    plt.figure(figsize=(8, 6))
    sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", vmin=-1, vmax=1)
    plt.title("Correlation Heatmap of Daily Returns")
    plt.savefig("output/correlation_heatmap.png")

def plot_bootstrap_histograms(bootstrap_df):
    plt.figure(figsize=(14, 8))
    metrics = bootstrap_df.columns
    for i, met in enumerate(metrics):
        plt.subplot(2, 3, i+1)
        plt.hist(bootstrap_df[met].dropna(), bins=30, alpha=0.75, color="purple")
        plt.title(f"Bootstrap Distribution: {met}")
        plt.xlabel(met)
        plt.ylabel("Frequency")
    plt.tight_layout()
    plt.savefig("output/bootstrap_histograms.png")

def plot_sector_weights(sector_weights):
    plt.figure(figsize=(10, 6))
    sector_weights.sort_values(ascending=False).plot(kind="bar", color="green")
    plt.title("Performance-based Sector Weights (Trailing 6 Months)")
    plt.xlabel("ETF")
    plt.ylabel("Weight")
    plt.grid(True)
    plt.savefig("output/sector_weights.png")

# --- Generate Visualizations ---
print("Generating visualizations...")

# 1. Plot Cumulative Returns
plot_cumulative_returns(strategies)

# 2. Plot Daily Return Histograms
daily_returns_strategies = {
    "Equity": equity_index_full.pct_change().dropna(),
    "Covered Call": covered_call_index_full.pct_change().dropna(),
    "Combined": combined_index.pct_change().dropna(),
    "SPY": spy_index.pct_change().dropna()
}
plot_daily_return_histograms(daily_returns_strategies)

# 3. Plot Drawdown Curves
plot_drawdown_curves(strategies)

# 4. Plot Rolling Metrics for Combined Portfolio
plot_rolling_metrics(combined_index, window=60)

# 5. Plot Correlation Heatmap of Daily Returns
plot_correlation_heatmap(daily_returns_strategies)

# 6. Plot Bootstrap Sensitivity Histograms
bootstrap_results = bootstrap_sensitivity(combined_index, n_iter=500, sample_frac=0.5)
plot_bootstrap_histograms(bootstrap_results)

# 7. Plot Sector Weights
sector_weights = compute_sector_weights(price_data, etf_list, lookback_days=126)
plot_sector_weights(sector_weights)

# 8. Compute and Export Risk Metrics
metrics_list = []
for label, series in strategies.items():
    cum_ret, ann_ret, ann_vol, sharpe, max_dd = compute_risk_metrics(series, risk_free=risk_free_equity)
    metrics_list.append({
        "Strategy": label,
        "Cumulative Return (%)": cum_ret * 100,
        "Annualized Return (%)": ann_ret * 100,
        "Annualized Volatility (%)": ann_vol * 100,
        "Sharpe Ratio": sharpe,
        "Max Drawdown (%)": max_dd * 100
    })
metrics_df = pd.DataFrame(metrics_list)
print("\nRisk Metrics Comparison:")
print(metrics_df)
metrics_df.to_excel("portfolio_risk_metrics.xlsx", index=False)
print("Risk metrics have been written to portfolio_risk_metrics.xlsx")



